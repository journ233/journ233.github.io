{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36983ae7-3600-48d0-a66c-215d64c69ed9",
   "metadata": {},
   "source": [
    "# Lecture 1030\n",
    "\n",
    "More pandas and charts with Altair using Berkeley 311 call data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1b2e7-095d-4c93-9a8f-c1537b84d12a",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "As usual, we'll import modules at the top of the notebook. This time, we don't need the `requests` module since we're not going to re-download the data from the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4a86",
   "metadata": {},
   "source": [
    "### What is Altair?\n",
    "\n",
    "[Altair](https://altair-viz.github.io/) is a data visualization library for Python. `matplotlib` is usually the first data viz module Python programmers learn, but Altair is easier to use. The Altair community uses the alias `alt` when importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15486cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de99a35-1017-4715-b297-5942d710295e",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "We did a lot of work last week cleaning up the Berkeley 311 calls. We don't need to redo that work since we exported a clean version called `berkeley_311_clean.csv`. \n",
    "\n",
    "Remember that a `csv` file is just a plain-text file. That means that the file, just as it is, cannot retain the **dtype** of a column.\n",
    "\n",
    "So this time when we import the data, we'll want to make sure that we set up the dtypes we do know and parse `datetime` dtypes correctly.\n",
    "\n",
    "I also want to set **Case_ID** to an `object` dtype instead of an `int` dtype. Why would I want to do this? You can't operate on **Case_ID** like it's a number. You aren't going to add up the Case_IDs. So it's better to import that column as an `object`.\n",
    "\n",
    "Last thing: where you saved this notebook file matters. Where does the file `berkeley_311_clean.csv` exist locally on your computer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b44844-0560-4c21-b73c-137aee48100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311 = pd.read_csv('../1023/berkeley_311_clean.csv', \n",
    "    dtype={\n",
    "        'Case_ID': object,\n",
    "    },\n",
    "    parse_dates=['Date_Opened', 'Date_Closed', 'Close_Time']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd6f27-d4f3-4425-82f3-e2323bf8129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9408d6-78a5-47da-a4a4-59815d9d351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ab503-ff9c-47b7-9659-a6768aedae37",
   "metadata": {},
   "source": [
    "The **Close_Time** column didn't get typed as `timedelta`. It doesn't look like it's possible to do so with `pd.read_csv()`. (There's [an open issue](https://github.com/pandas-dev/pandas/issues/8185) on the pandas repo as of today's lecture.) So we'll just set it this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e9779-9253-4152-b802-1e05da7e36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311['Close_Time'] = pd.to_timedelta(berkeley_311['Close_Time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe493c-561a-4f1a-b11c-97042027f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83f7ad-5147-4b12-9022-53df7311f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654471a-2b39-4273-9b73-53fc587c73c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore data\n",
    "\n",
    "What do I do if I don't have a question yet? I'm not really sure what to look into with this 311 data. So I'm going to explore it a little bit. I might do some analysis, I might not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4072e-b103-4b9f-9c9d-0a6f2bd321e1",
   "metadata": {},
   "source": [
    "### Categories of incidents in 2022\n",
    "\n",
    "I'm curious about the different categories of incidents in the year 2022.\n",
    "\n",
    "First, I'll create a new dataframe `berkeley_311_2022` that subsets the `berkeley_311` data to just the cases that were open in 2022. (We discussed this last week, but subsetting data is a way to filter data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff1e03-6a56-4de0-a5d9-9a8a15581aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022 = berkeley_311.loc[\n",
    "    (berkeley_311['Date_Opened'] >= '2022-01-01') &\n",
    "    (berkeley_311['Date_Opened'] < '2023-01-01') # Why don't I use `berkeley_311['Date_Opened'] <= '2022-12-31']` ?\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e461e-27f7-4ed9-98a1-139092d1cc09",
   "metadata": {},
   "source": [
    "Let's look at that expression above. \n",
    "- I used [`df.loc[ expression ]` because it is more performant than subsetting using just `df[ expression ]`. Either way is fine for your work. There are many ways to subset data in pandas; here's some more information about [those ways](https://pandas.pydata.org/docs/user_guide/indexing.html).\n",
    "- We're using `&` (instead of `and`). Remember our first lectures: `&` is a [bitwise operator](https://docs.python.org/3/reference/expressions.html#binary-bitwise-operations), while `and` is a [logical or boolean operator](https://docs.python.org/3/reference/expressions.html#boolean-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a9140-1da7-477b-95ed-28d316e56cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ab4db-04f6-4d5e-b146-a2b5301e20a2",
   "metadata": {},
   "source": [
    "One thing I'm seeing immediately is that the index of this new dataframe `berkeley_311_2022` looks kind of weird. It's no longer sequential. I can reset the index to make it sequential by using `df.reset_index(drop=True)`.\n",
    "\n",
    "```python\n",
    "berkeley_311_2022 = berkeley_311_2022.reset_index(drop=True)\n",
    "```\n",
    "\n",
    "Alternatively, instead of copying the original dataframe with df.copy(), we can reset the index at the same time we subset the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea6567-4d13-455b-a676-e2d96a173af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022 = berkeley_311.loc[\n",
    "    (berkeley_311['Date_Opened'] >= '2022-01-01') &\n",
    "    (berkeley_311['Date_Opened'] < '2023-01-01') \n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e565a-446c-4206-8290-88600867b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d871263-2665-462b-8a7e-c4a424252caf",
   "metadata": {},
   "source": [
    "#### Let's view all the unique values of **Request_Category**\n",
    "\n",
    "You can call `series.unique()` on a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f2e3b-76f2-4f20-aacf-fb5782bdd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022['Request_Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e245d-de55-44b4-bab2-939c8e5e7db7",
   "metadata": {},
   "source": [
    "I'm interested in getting a count of those categories for 2022. How can I achieve this? We'll use the method `series.value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2658-0c29-4166-8d3c-c282d6129ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022['Request_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8fa57-9949-4f20-9c43-dd009f65336b",
   "metadata": {},
   "source": [
    "You can also get the `value_counts()`  for two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4335715-d452-489e-8800-2961f513945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022[['Request_Category', 'Request_SubCategory']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38c542-d190-47dc-b19c-770ca9f73973",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_2022[['Request_Category', 'Request_SubCategory']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce5e43-5ec9-4134-b906-d44672ef385a",
   "metadata": {},
   "source": [
    "OK, so let's just look at the major topline categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274c65b-c1d3-4856-9c3a-e5598724cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_2022 = berkeley_311_2022['Request_Category'].value_counts()\n",
    "category_counts_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1f05f-58a7-4979-93c9-aacdd114c117",
   "metadata": {},
   "source": [
    "#### Convert series to dataframe\n",
    "The `.value_counts()` method creates a series, not a dataframe. We'll convert that to a pandas dataframe with `to.frame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e90bb5-0571-4095-8e6c-7b0599edbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_2022 = category_counts_2022.to_frame()\n",
    "category_counts_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10abc96-5c14-476e-9651-ad1f6cfa2c88",
   "metadata": {},
   "source": [
    "#### Resetting the index\n",
    "\n",
    "In this dataframe, the index is no longer a series of sequential integers like we've seen before. We'll convert **Request_Category** to a column, from an index. That will make the dataframe easier to use later.\n",
    "\n",
    "We're going to use `df.reset_index()`. This time, we're not going to use the `drop=True` argument because we want to create a wholly new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58ff39-7700-4369-bccd-a7df61c32e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_2022 = category_counts_2022.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d9f6d-a1c1-49e1-8747-a07d81dd4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79271c9-5b60-4c1f-9993-fd4c0af87803",
   "metadata": {},
   "source": [
    "Looks like `Refuse and Recycling`, along with `General Questions/information` and `Streets, Utilities, and Transportation` were among the top issues in 2022. Might be worth looking into some of the sub-categories later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3924c-f0c7-4686-a187-a28e1ed604bb",
   "metadata": {},
   "source": [
    "#### Rename columns\n",
    "\n",
    "Let's change the column names, while we're at it.\n",
    "\n",
    "You can replace _all_ the columns in a dataframe in one sweep with the following code:\n",
    "\n",
    "```python\n",
    "category_counts_2022.columns  = ['category', 'cases']\n",
    "```\n",
    "\n",
    "If you have a lot of columns, that's going to be a long list. But if you have a lot of columns to rename, the method above might be easier. If you have only one column to rename out of many columns, you'll want to use the following code:\n",
    "\n",
    "```python\n",
    "category_counts_2022.rename(columns={'Request_Category': 'category'}, inplace=True)\n",
    "```\n",
    "\n",
    "The first argument in the `df.rename()` method is `columns`. And what do we set columns to? We set it to a Python dictionary where the \"key\" is the original column name and the \"value\" is the new column name: `{'Request_Category': 'category'}`. \n",
    "\n",
    "The second argument is `inplace=True`. That tells us to change the `category_counts_2022` \"in place\" or without having to reset the dataframe variable. A lot of the methods in pandas return a new dataframe instead of altering the original dataframe. An alternative to using `inplace` is the following code:\n",
    "\n",
    "```python\n",
    "category_counts_2022 = category_counts_2022.rename(columns={'Case_ID': 'Count'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae732f-29a1-48a2-9dd7-da2a9ef2bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_2022.columns  = ['category', 'cases']\n",
    "category_counts_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7241ff78-2347-40cb-a832-de6943b46883",
   "metadata": {},
   "source": [
    "#### Let's visualize this summary table!\n",
    "\n",
    "Before we run the Altair code below, let's take a closer look:\n",
    "\n",
    "```python\n",
    "alt.Chart(category_counts_2022).mark_bar().encode(\n",
    "    x='cases',\n",
    "    y='category'\n",
    ").properties(\n",
    "    title='Berkeley 311 cases in 2022'\n",
    ")\n",
    "```\n",
    "The first part of the code `alt.Chart()` requires you to fill the first argument with a dataframe, in this case `category_counts_2022`.\n",
    "\n",
    "The next part of the code `mark_bar()` specifies a bar chart. (If you want a line chart, you'd use `mark_line()`.)\n",
    "\n",
    "After that, `.encode()` tells Altair which columns to use for the `x` and `y` axes.\n",
    "\n",
    "If you want to add a title, you'd use Altair's `.properties()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2edf07-5287-4ac8-b1bc-7cea732e1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(category_counts_2022).mark_bar().encode(\n",
    "    x='cases',\n",
    "    y='category'\n",
    ").properties(\n",
    "    title='Berkeley 311 cases in 2022'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17766d00-898c-4851-940e-c71cde5f8671",
   "metadata": {},
   "source": [
    "Annoyingly, this doesn't sort the chart in descending order, which I prefer. This is the code to do, it's a little more complicated:\n",
    "\n",
    "```python\n",
    "alt.Chart(category_counts_2022).mark_bar().encode(\n",
    "    x='cases',\n",
    "    y=alt.Y('category', sort='-x')\n",
    ").properties(\n",
    "    title='Berkeley 311 cases in 2022'\n",
    ")\n",
    "```\n",
    "\n",
    "Basically, you have to create a custom Y encoding with the format: `alt.Y('column_name', sort='-x')`. `-x` means the inverse of the x-axis, in this case. This is not intuitive, I thinkÂ â€” it's just something you'd have to look up in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda2835-ae2e-4192-98ed-f6879edb6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(category_counts_2022).mark_bar().encode(\n",
    "    x='cases',\n",
    "    y=alt.Y('category', sort='-x')\n",
    ").properties(\n",
    "    title='Berkeley 311 cases in 2022'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7377df5-bdb5-4c31-847f-93e85cdb4923",
   "metadata": {},
   "source": [
    "### Count how many incidents per year\n",
    "\n",
    "The next thing I'd like to do is get a count of all the incidents by year. However, I know from the last notebook that the data for 2010 and 2023 are not complete. So I need to subset.\n",
    "\n",
    "Below, I'm creating a new dataframe called `berkeley_311_complete` that limits the `berkeley_311` dataframe to ones in which the **Date_Opened** value starts on or after January 1, 2011 and is before January 1, 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9df26-55d0-4b18-b74c-4c70ed06bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_complete = berkeley_311.loc[\n",
    "    (berkeley_311['Date_Opened'] >= '2011-01-01') &\n",
    "    (berkeley_311['Date_Opened'] < '2023-01-01')\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d23ae0-c7cb-4aef-892f-2dcb7186683d",
   "metadata": {},
   "source": [
    "#### Aggregate with `df.groupby()`\n",
    "\n",
    "To aggregate the data, we're going to use a method called `df.groupby()`. Normally, when we group data, we'll group them by columns, like so:\n",
    "\n",
    "```python\n",
    "df.groupby(['Column 1', 'Column 2'])\n",
    "```\n",
    "\n",
    "You can also just group by a single column, like we're doing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede9755-5bf3-4500-a026-0d9caeeeca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_complete.groupby(['Request_Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc2c97-132c-4c94-95c9-de30270631b0",
   "metadata": {},
   "source": [
    "Running a `df.groupby()` doesn't do anything on its own, it just creates a pandas DataFrameGroupBy object. You have to follow it up with some kind of other method. Below, we're calling `df.count()` on the DataFrameGroupBy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac8186-8a7b-4bf0-b127-83fa2505076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_complete.groupby(['Request_Category']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5895747-1866-4409-bc16-c04492d1c513",
   "metadata": {},
   "source": [
    "It's kind of like getting `value_counts()` on a column.\n",
    "\n",
    "OK! So that's a new dataframe, with a little too much info. We're not going to do anything with this particular dataframe; I just wanted to show you how `groupby()` works so we can look specifically at how to use it for datetimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd163aa-387d-49a6-a223-60800a3542b4",
   "metadata": {},
   "source": [
    "#### Use df.groupby() with datetimes\n",
    "\n",
    "Now that we know a little bit about the `groupby()` method, let's figure out how to use this with dates.\n",
    "\n",
    "It's a little tricky to group by datetimes. Instead of grouping by just a column name, we're going to have to use a method called `pd.Grouper`. \n",
    "\n",
    "Before we run the code below, let's look at the different arguments within the method:\n",
    "\n",
    "```python\n",
    "pd.Grouper(key='Date_Opened', axis=0, freq='A')\n",
    "```\n",
    "\n",
    "The `key` argument lists the column. The `axis` argument is `0`. In pandas, axis 0 is rows and axis 1 means columns. That means you can do column-wise calculations if your data is shaped differently. \n",
    "\n",
    "The `freq` argument is `A`, which stands for \"annual\" or year (`Y` also works, but isn't documented). You can see other [frequency arguments](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases) in the official pandas documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeed61c-d7b9-4a38-a924-d534b55f3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_311_complete.groupby([pd.Grouper(key='Date_Opened', axis=0, freq='A')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694c286-56d7-44df-8fc0-718372a4f115",
   "metadata": {},
   "source": [
    "Remember that running a `df.groupby()` doesn't do anything on its own; you have to chain that command with some kind of other method. Below, we're calling `df.count()` on the DataFrameGroupBy object. Finally, we're calling our new dataframe `annual_cases`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491f91f-678a-4641-a38f-b3f0878e749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases = berkeley_311_complete.groupby([pd.Grouper(key='Date_Opened', axis=0, freq='A')]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf860d-effb-4785-afb7-6b10f7054af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65591f-8aef-44c1-af9d-d91db9150c84",
   "metadata": {},
   "source": [
    "Now let's subset just the one column, **Case_ID**, from annual cases, then reset the index so that `Date_Opened` becomes a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f28d87-f632-497a-a898-7a9cbb21f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases = annual_cases[['Case_ID']].reset_index()\n",
    "annual_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6d9c7-9cfc-4232-b813-9c7068891da1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7a777-fa12-4e22-a172-b3f425f45b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases.rename(columns={'Case_ID': 'cases'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01873b93-326f-41c6-8bd0-3e5eb7e41e3a",
   "metadata": {},
   "source": [
    "Let's take a look at our nicely named summary table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba7eb5-eb0e-4e89-9de6-e0175a99cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be7c37-4985-4f4b-9c8a-2f375881fe3f",
   "metadata": {},
   "source": [
    "Let's create a new column in `annual_cases` called **Year**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b3c93-2fc8-4754-927b-8849f87eb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases['year'] = annual_cases['Date_Opened'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284279df-8fce-4b0e-a28d-f9f0c03dad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6799e-68cb-4e90-8120-51c76b6c9370",
   "metadata": {},
   "source": [
    "At this point, I don't need the **Date_Opened** column anymore. So I can subset the dataframe with just the two columns I need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0edac2-7eab-4699-8e72-2fdc8ed8a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases = annual_cases[['year', 'cases']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd71e8-1ec8-467b-b464-75928c501d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0234b2-1115-4fb7-a124-ed479cae8958",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5fb88-47e7-49f4-860c-6cdc4dd7d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(annual_cases).mark_bar().encode(\n",
    "    x='year',\n",
    "    y='cases'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c1b48-6800-4fc9-bd3b-ae258c9d6cc6",
   "metadata": {},
   "source": [
    "That's pretty cool, but **Year** shows up kind of weird. Let's make a very small alteration to the code.\n",
    "\n",
    "Before you run the code below, notice that after `Year` there's a colon and an `O`. The `O` is shorthand for \"ordinal,\" and tells Altair to treat `Year` as if it's a discrete quantity (a.k.a. integers), not a continuous quantity (e.g. a number with decimals). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64f245-f38e-45b9-bf16-331b3694c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(annual_cases).mark_bar().encode(\n",
    "    x='year:O',\n",
    "    y='cases'\n",
    ").properties(\n",
    "    title='Berkeley 311 calls: Number of cases'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb766e-c38a-4195-b026-bd65333f4c57",
   "metadata": {},
   "source": [
    "You can read about more [Altair encoding types](https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types) in the documentation. It's helpful to get familiar with those encoding types in the event your chart doesn't look quite right. Try adjusting the encoding types on your own to see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf8468-d644-4584-90c3-464852af3881",
   "metadata": {},
   "source": [
    "### Median Close_Time by year\n",
    "\n",
    "Now I'd like to try to get the median length of time it takes to close a case by year. I'm going to try something I think will work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb164a3-6ccf-4c3d-bba9-5c3d9810b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time = berkeley_311_complete.groupby([pd.Grouper(key='Date_Opened', axis=0, freq='A') ]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3599d6b-5b55-4b49-975f-cb556daae6f6",
   "metadata": {},
   "source": [
    "It looks like that didn't work! Sometimes pandas doesn't work the way you want it to. The problem is that we have too many columns that don't support calculating a median (for example, a bunch of text-only columns.) So we'll have to subset the dataframe for just the two columns we want. Then we can run the `groupby()` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e17c1-0c85-48b4-a688-d087cb6a4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time = berkeley_311_complete[\n",
    "    ['Date_Opened', 'Close_Time']\n",
    "].groupby([pd.Grouper(key='Date_Opened', axis=0, freq='A') ]).median()\n",
    "\n",
    "median_close_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f952b2-677c-4087-a500-ed8a389f1591",
   "metadata": {},
   "source": [
    "Below, I'm creating a new column called **year**, as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ab008-a2a1-4410-99f5-83e352affdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time['year'] = median_close_time['Date_Opened'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b567e3-5e1f-41a7-a0e6-79fdae8f9863",
   "metadata": {},
   "source": [
    "Oops! That didn't work because I forgot to reset the index. (Please don't copy these \"mistakes\" into your homework, lol.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d388e4c-8874-4854-9d79-36ca77fcdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time = median_close_time.reset_index()\n",
    "median_close_time['year'] = median_close_time['Date_Opened'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d95dd-5c2c-4cdf-b833-84556c8e8f6f",
   "metadata": {},
   "source": [
    "Renaming the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f85ce-92e1-445a-8308-319a7a9341b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time.columns = ['date_opened', 'close_time', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8a21c-e0ee-4fee-880b-e51fe2cc73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b021db6-91df-43b4-ad92-4af24d0b6f3f",
   "metadata": {},
   "source": [
    "Subsetting the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4001894-9cbe-4e81-a418-f9fee5226c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time = median_close_time[['year', 'close_time']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fde0a-6b9c-4a8f-8ef5-f5a32aeda80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8528c-e1e1-4aca-aa7a-fcaa2cd6a773",
   "metadata": {},
   "source": [
    "Let's make a chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e99e4e-dfa6-4699-a7ee-68d7cbcb205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(median_close_time).mark_bar().encode(\n",
    "    x='year:O',\n",
    "    y='close_time',\n",
    ").properties(\n",
    "    title='Berkeley 311 calls: Median resolution time'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d192ae-1c56-41d6-a96e-0fab866a15f6",
   "metadata": {},
   "source": [
    "ARRGHHH! That didn't work. Let's look at the error: \n",
    "```\n",
    "ValueError: Field \"close_time\" has type \"timedelta64[ns]\" which is not supported by Altair. Please convert to either a timestamp or a numerical value.\n",
    "```\n",
    "It sounds like I need to convert `timedelta` to a different unit. Let's try, er, nanoseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609415a1-20f6-4ac5-b965-ab90fd8a0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time['close_time_nanoseconds'] = median_close_time['close_time'].astype(int)\n",
    "median_close_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbca4f-e912-406b-ab07-c10b798751b1",
   "metadata": {},
   "source": [
    "Let's try this again! I'm going to use a subset of the dataframe within the chart method argument because I don't want to create a whole new dataframe (Altair won't accept any dataframe at all with a dtype it can't support). Use your discretion for when you want to do something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d22da-f934-4e9d-976a-93db0318d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(median_close_time[['year', 'close_time_nanoseconds']]).mark_bar().encode(\n",
    "    x='year:O',\n",
    "    y='close_time_nanoseconds',\n",
    ").properties(\n",
    "    title='Berkeley 311 calls: Median resolution time'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4141604-79f2-4c1e-89f1-c4f8c76117dc",
   "metadata": {},
   "source": [
    "### Merge two dataframes\n",
    "\n",
    "Now I'd like to merge `median_close_time` and `annual_cases`. Why? Mostly because I'd like to teach you how to merge dataframes. But you can get a neat summary table this way. Let's look at both dataframes again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb07302-62f5-4557-94e2-d750aadff1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444606d4-0d8f-4ca7-b686-84896315b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_close_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17de8f-5b64-497e-9a72-53a250144257",
   "metadata": {},
   "source": [
    "Let's look at the arguments in `pd.merge()` before we run it:\n",
    "\n",
    "```python\n",
    "pd.merge(\n",
    "    df1,\n",
    "    df2,\n",
    "    how='outer', # other options: 'inner', 'left', 'right'\n",
    "    on='Year',\n",
    "    validate='1:1' # options: '1:m', 'm:m', 'm:1'\n",
    ")\n",
    "```\n",
    "1. The first argument is the left-hand dataframe. The second argument is the right-hand dataframe. Why is it important that there's an order to dataframes? \n",
    "\n",
    "2. The `how` argument tells pandas how we'll merge the two dataframes. In this case, we'll use `outer`. But we could also use `left`, `right`, or `inner`. What does this mean? [Here are some visual examples of how joins work.](https://docs.google.com/spreadsheets/d/1SYukPLfuIkiqhIEPeXWXDBqClife8SoEgvHyBxw_ehs/edit) In this case, it doesn't matter which value we use for `how` because both dataframes have 10 rows with matching years. \n",
    "\n",
    "3. The `on` argument tells pandas which column key we're going to match on. In this case, we want the years to match up.\n",
    "\n",
    "4. The `validate` argument is optional, but I recommend you learn how to use it. The value we used, `'1:1'` means that 1 row in the left-hand dataframe will match up to exactly 1 row in the right-hand dataframe. The option `1:m` means that 1 row in the left-hand dataframe could match up to **many** rows in the right-hand dataframe. (Any time you use `m`, you're telling pandas that there _might_ be multiple matches.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccbbcc-de06-4900-bc6c-1282922c4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_summary = pd.merge(\n",
    "    annual_cases,\n",
    "    median_close_time,\n",
    "    on='year',\n",
    "    how='outer',\n",
    "    validate='1:1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a62ba7-a302-493a-8b9b-d3ff6c9d524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b629f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_summary.to_csv('berkeley_311_annual_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fb04f89b61a62c03d47bf47357bc88692aa1a75ad45736fa559ef9e95df90447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
